# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZDNv-dUNZdpNB0LQ6ED8CbyJXc40H_nj

<h1><center>Simple Linear Regression</center></h1>

<h1>Table of contents</h1>

<div class="alert alert-block alert-info" style="margin-top: 20px">
    <ol>
        <li>Understanding the Data</li>
        <li>Reading the data in</li>
        <li>Data Exploration</li>
        <li>Simple Regression Model</li>
    </ol>
</div>
<br>
<hr>

## Importing Needed packages
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import pandas as pd
import pylab as pl
import numpy as np
# %matplotlib inline

"""<h2 id="reading_data">Reading the data in</h2>"""

df = pd.read_csv("http://bit.ly/w-data")

# take a look at the dataset
df.head()

"""<h2 id="data_exploration">Data Exploration</h2>
Lets first have a descriptive exploration on our data.
"""

# summarize the data
df.describe()

"""Let's plot our data points on 2-D graph to eyeball our dataset and see if we can manually find any relationship between the data. We can create the plot with the following script:"""

# Plotting the distribution of scores
df.plot(x='Hours', y='Scores', style='r')  
plt.title('Hours vs Percentage')  
plt.xlabel('Hours Studied')  
plt.ylabel('Percentage Score')  
plt.show()

"""**From the graph above, we can clearly see that there is a positive linear relation between the number of hours studied and percentage of score.**

#### Creating train and test dataset
"""

X = df.iloc[:, :-1].values  
y = df.iloc[:,1 ].values

from sklearn.model_selection import train_test_split  
X_train, X_test, y_train, y_test = train_test_split(X, y, 
                            test_size=0.2, random_state=0)

"""### **Training the Algorithm**
We have split our data into training and testing sets, and now is finally the time to train our algorithm.
"""

from sklearn.linear_model import LinearRegression  
regr = LinearRegression()  
regr.fit(X_train, y_train) 

print("Training complete.")

plt.scatter(X_train, y_train,  color='blue')
plt.plot(X_train, regr.coef_*X_train + regr.intercept_, '-r')
plt.xlabel("Hours")
plt.ylabel("Score")

"""### **Making Predictions**
Now that we have trained our algorithm, it's time to make some predictions.
"""

print(X_test) # Testing data - In Hours
y_pred = regr.predict(X_test) # Predicting the scores

# Comparing Actual vs Predicted
df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  
df

# You can also test with your own data
hours = np.asanyarray(float(input()))
hours = hours.reshape(-1,1)
own_pred = regr.predict(hours)
print("No of Hours = {}".format(*hours))
print("Predicted Score = {}".format(own_pred[0]))

"""### **Evaluating the model**

The final step is to evaluate the performance of algorithm. This step is particularly important to compare how well different algorithms perform on a particular dataset. For simplicity here, we have chosen the mean square error. There are many such metrics.
"""

from sklearn import metrics
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))